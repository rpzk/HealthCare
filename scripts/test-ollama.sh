#!/bin/bash

# Test script para verificar a integra√ß√£o com o Ollama
# Este script testa a comunica√ß√£o com o servidor Ollama e realiza uma infer√™ncia b√°sica

echo "üîç Teste de Integra√ß√£o com Ollama"
echo "=================================="

# Verificar se o Ollama est√° em execu√ß√£o
echo "1. Verificando se o servi√ßo Ollama est√° rodando..."

if ! docker ps | grep -q healthcare-ollama; then
  echo "‚ùå Servi√ßo Ollama n√£o encontrado! Iniciando o servi√ßo..."
  docker-compose up -d ollama
  echo "‚è≥ Aguardando inicializa√ß√£o do Ollama (10s)..."
  sleep 10
else
  echo "‚úÖ Servi√ßo Ollama est√° rodando."
fi

# Verificar se o modelo est√° dispon√≠vel
echo "2. Verificando modelos dispon√≠veis no Ollama..."
MODELOS=$(docker-compose exec ollama ollama list)
echo "$MODELOS"

# Extrair o modelo do arquivo .env ou usar o padr√£o
if [ -f .env ]; then
  OLLAMA_MODEL=$(grep OLLAMA_MODEL .env | cut -d '=' -f2)
fi

if [ -z "$OLLAMA_MODEL" ]; then
  OLLAMA_MODEL="llama3"
  echo "‚ÑπÔ∏è Modelo n√£o definido no .env, usando o padr√£o: $OLLAMA_MODEL"
fi

# Verificar se o modelo desejado j√° est√° dispon√≠vel
if echo "$MODELOS" | grep -q "$OLLAMA_MODEL"; then
  echo "‚úÖ Modelo $OLLAMA_MODEL j√° est√° dispon√≠vel."
else
  echo "‚ö†Ô∏è Modelo $OLLAMA_MODEL n√£o encontrado. Baixando..."
  docker-compose exec ollama ollama pull $OLLAMA_MODEL
  if [ $? -eq 0 ]; then
    echo "‚úÖ Modelo $OLLAMA_MODEL baixado com sucesso."
  else
    echo "‚ùå Falha ao baixar o modelo $OLLAMA_MODEL."
    exit 1
  fi
fi

# Testar o modelo com uma consulta m√©dica b√°sica
echo "3. Testando infer√™ncia do modelo com consulta m√©dica..."
echo "Enviando prompt: 'Quais s√£o os sintomas comuns de diabetes?'"

RESPONSE=$(docker-compose exec ollama ollama run $OLLAMA_MODEL "Atue como um assistente m√©dico e responda de forma sucinta: Quais s√£o os sintomas comuns de diabetes?")

# Exibir resposta
echo "Resposta do modelo $OLLAMA_MODEL:"
echo "-----------------------------------"
echo "$RESPONSE"
echo "-----------------------------------"

# Testar a integra√ß√£o da API
echo "4. Testando API do Ollama..."

TEST_API=$(docker-compose exec ollama curl -s -X POST http://localhost:11434/api/generate -d '{
  "model": "'$OLLAMA_MODEL'",
  "prompt": "Liste 3 recomenda√ß√µes para preven√ß√£o de hipertens√£o.",
  "stream": false
}')

if echo "$TEST_API" | grep -q "response"; then
  echo "‚úÖ API do Ollama est√° funcionando corretamente."
  
  # Mostrar apenas a resposta formatada
  RESPONSE=$(echo "$TEST_API" | grep -o '"response":"[^"]*"' | sed 's/"response":"//;s/"//')
  echo "Resposta da API:"
  echo "-----------------------------------"
  echo "$RESPONSE"
  echo "-----------------------------------"
else
  echo "‚ùå Falha ao comunicar com a API do Ollama."
  echo "$TEST_API"
  exit 1
fi

echo "5. Verificando integra√ß√£o com a aplica√ß√£o..."
# Verificar se a aplica√ß√£o est√° rodando
if ! docker ps | grep -q healthcare-app; then
  echo "‚ö†Ô∏è Aplica√ß√£o n√£o est√° rodando. Iniciando apenas para teste..."
  docker-compose up -d app
  sleep 5
fi

# Verificar logs para confirmar que est√° usando o Ollama
echo "Verificando logs da aplica√ß√£o para confirmar integra√ß√£o com Ollama..."
docker-compose logs --tail=50 app | grep -i "ollama"

echo "=================================="
echo "‚úÖ Teste de integra√ß√£o completo!"
echo "‚úÖ Ollama est√° configurado e funcionando corretamente."
echo "‚úÖ O modelo $OLLAMA_MODEL est√° pronto para uso."
echo "=================================="
echo "Para usar a aplica√ß√£o completa: npm run start:ollama"
echo "=================================="
